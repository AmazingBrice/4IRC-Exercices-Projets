{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "tp1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oMF_IY6ZSpu"
      },
      "source": [
        "### Objectifs\n",
        "\n",
        "- Analyser et travailler avec des fichiers CSV, TSV et JSON\n",
        "- Interroger des sources de données externes\n",
        "- Analyses de données\n",
        "\n",
        "#### Exercices\n",
        "\n",
        "1.  Installation et mise en place de pip, scikit-learn et jupyter\n",
        "2.  Analyse et lecture de fichiers CSV/TSV\n",
        "3.  Analyse et lecture des fichiers JSON\n",
        "4.  Interrogation de sources de données externes (API)\n",
        "5.  Effectuer des analyses de données classiques\n"
      ],
      "id": "2oMF_IY6ZSpu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmvP7hUvZSp2"
      },
      "source": [
        "#### Exercice 1.1\n",
        "\n"
      ],
      "id": "UmvP7hUvZSp2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbpjdENoZSp3"
      },
      "source": [
        "##### Installation\n",
        "\n",
        "Exécutez les commandes suivantes sur vos machines virtuelles\n",
        "\n"
      ],
      "id": "sbpjdENoZSp3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIuAJrPsZSp3"
      },
      "source": [
        "**pip**\n",
        "\n",
        "Pour installer `pip`, vous devez exécuter les commandes suivantes sur votre terminal :\n",
        "\n",
        "**Note** : Veuillez noter que toutes les lignes commençant par \"$\" doivent être exécutées sur le terminal."
      ],
      "id": "tIuAJrPsZSp3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpbcNGMYZSp4"
      },
      "source": [
        "`$ sudo apt update`\n",
        "\n",
        "`$ sudo apt install python3-dev`\n",
        "\n",
        "`$ sudo apt install python3-pip`"
      ],
      "id": "PpbcNGMYZSp4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQa32ez7ZSp4"
      },
      "source": [
        "Installation de virtualenv"
      ],
      "id": "CQa32ez7ZSp4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_JjahDJZSp5"
      },
      "source": [
        "`$ sudo apt install virtualenv`"
      ],
      "id": "0_JjahDJZSp5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXSeW8rVZSp5"
      },
      "source": [
        "Installation dans virtualenv\n",
        "\n"
      ],
      "id": "fXSeW8rVZSp5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAcbhfM1ZSp5"
      },
      "source": [
        "`$ virtualenv --system-site-packages -p python3 env`"
      ],
      "id": "yAcbhfM1ZSp5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtOJMDYDZSp6"
      },
      "source": [
        "`$ source env/bin/activate`"
      ],
      "id": "QtOJMDYDZSp6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDPKXrJ6ZSp6"
      },
      "source": [
        "Installation de Jupyter"
      ],
      "id": "IDPKXrJ6ZSp6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjIlUZdPZSp6"
      },
      "source": [
        "`$ python3 -m pip install --upgrade --force-reinstall  --no-cache jupyter`"
      ],
      "id": "GjIlUZdPZSp6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLo0WX-tZSp6"
      },
      "source": [
        "Installation de scikit-learn"
      ],
      "id": "ZLo0WX-tZSp6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf4DqE17ZSp7"
      },
      "source": [
        "`$ python3 -m pip install scikit-learn`"
      ],
      "id": "gf4DqE17ZSp7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvjr0yEiZSp7"
      },
      "source": [
        "Installation de  numpy"
      ],
      "id": "Fvjr0yEiZSp7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxoYxCAvZSp7"
      },
      "source": [
        "`$ python3 -m pip install numpy`"
      ],
      "id": "IxoYxCAvZSp7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKzux45hZSp7"
      },
      "source": [
        "Installation de  pandas"
      ],
      "id": "WKzux45hZSp7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWWL7pj6ZSp8"
      },
      "source": [
        "`$ python3 -m pip install pandas`"
      ],
      "id": "KWWL7pj6ZSp8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6e6OfsPZSp8"
      },
      "source": [
        "Installation de matplotlib"
      ],
      "id": "P6e6OfsPZSp8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA-d_KNkZSp8"
      },
      "source": [
        "`$ python3 -m pip install matplotlib`"
      ],
      "id": "cA-d_KNkZSp8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYTRXLHyZSp8"
      },
      "source": [
        "##### Hello World!\n",
        "\n",
        "Si votre installation est réussie, vous pouvez lancer\n",
        "\n"
      ],
      "id": "FYTRXLHyZSp8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo-HZctEZSp9"
      },
      "source": [
        "`$ mkdir TP1 && cd TP1`\n",
        "\n",
        "`$ jupyter notebook`"
      ],
      "id": "Uo-HZctEZSp9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcQUperOZSp9"
      },
      "source": [
        "Une nouvelle page apparaîtra sur votre navigateur et vous verrez l'image suivante ![](attachment:../../images/jupyter.png)\n",
        "\n",
        "Cliquez sur l'onglet \"Running\". Vous ne voyez aucun notebook en cours d'exécution (si c'est la première fois que vous utilisez jupyter).\n",
        "![](attachment:../../images/jupyterrunning.png)\n",
        "\n",
        "Retournez à l'onglet \"Files\", cliquez sur \"New\" et choisissez Python3 sous\n",
        "Notebook  ![](attachment:../../images/jupyternotebook.png)\n",
        "\n",
        "Un nouvel onglet s'ouvrira comme indiqué ci-dessous. Inscrivez le code suivant dans la cellule.\n",
        "\n"
      ],
      "id": "lcQUperOZSp9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H7SL8IDZSp9",
        "outputId": "d26c1652-b7f2-45da-cb03-cabc59964c20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Hello World!\")"
      ],
      "id": "3H7SL8IDZSp9",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello World!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o0Kn3drZSp-"
      },
      "source": [
        "![](attachment:../../images/jupyterprogram.png)\n",
        "\n",
        "Vous pouvez vous déplacer dans n'importe quelle cellule et appuyer sur \"Run\".\n",
        "\n",
        "Par défaut, votre ordinateur portable est nommé \"Untitled\". Vous pouvez le renommer comme indiqué ci-dessous, en cliquant sur le nom \"Untitled\" et en lui donnant un nouveau nom.\n",
        "\n",
        "![](attachment:../../images/jupyterrenamenotebook.png)\n",
        "\n",
        "Retournez maintenant à l'onglet \"Files\" et vous pouvez voir le Notebook renommé.\n",
        "Vous pouvez cliquer sur votre Notebook à tout moment pour continuer à travailler.\n",
        "\n",
        "![](attachment:../../images/jupyternotebooks.png)\n",
        "\n",
        "Maintenant, continuons à travailler sur votre Notebook actuel. Ecrivez le code suivant pour vérifier si scikit est correctement installé.\n",
        "\n",
        "Le code ci-dessous indique les ensembles de données disponibles de scikit.\n"
      ],
      "id": "3o0Kn3drZSp-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdaL4unPZSp-",
        "outputId": "100d6066-6ed2-4165-de43-1136a6896600",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "print(datasets.__all__)"
      ],
      "id": "BdaL4unPZSp-",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['clear_data_home', 'dump_svmlight_file', 'fetch_20newsgroups', 'fetch_20newsgroups_vectorized', 'fetch_lfw_pairs', 'fetch_lfw_people', 'fetch_olivetti_faces', 'fetch_species_distributions', 'fetch_california_housing', 'fetch_covtype', 'fetch_rcv1', 'fetch_kddcup99', 'fetch_openml', 'get_data_home', 'load_boston', 'load_diabetes', 'load_digits', 'load_files', 'load_iris', 'load_breast_cancer', 'load_linnerud', 'load_sample_image', 'load_sample_images', 'load_svmlight_file', 'load_svmlight_files', 'load_wine', 'make_biclusters', 'make_blobs', 'make_circles', 'make_classification', 'make_checkerboard', 'make_friedman1', 'make_friedman2', 'make_friedman3', 'make_gaussian_quantiles', 'make_hastie_10_2', 'make_low_rank_matrix', 'make_moons', 'make_multilabel_classification', 'make_regression', 'make_s_curve', 'make_sparse_coded_signal', 'make_sparse_spd_matrix', 'make_sparse_uncorrelated', 'make_spd_matrix', 'make_swiss_roll']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57M7nKhGZSp-"
      },
      "source": [
        "![](attachment:../../images/jupyterscikit.png)\n",
        "\n",
        "Maintenant, vous êtes prêt à exécuter le code !\n",
        "\n",
        "**Note:**, Vous pouvez arrêter le Notebook Jupyter à tout moment en tapant \"Ctrl+c\" sur le terminal et en appuyant sur \"y\" pour confirmer l'arrêt.\n"
      ],
      "id": "57M7nKhGZSp-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q0eOg3TZSp_"
      },
      "source": [
        "#### Exercice 1.2\n",
        "\n",
        "\n",
        "La plupart du temps, nous travaillons avec des fichiers CSV (comma-separated values) pour l'analyse des données. Un fichier CSV est constitué d'une ou plusieurs lignes et chaque ligne comporte une ou plusieurs valeurs séparées par des virgules. On peut considérer chaque ligne comme une ligne et chaque valeur d'une ligne comme une valeur de colonne. La première ligne est parfois utilisée pour décrire les noms des colonnes.\n",
        "\n",
        "\n",
        "Copier le fichier\n",
        "[pl.csv](../../data/pl.csv) dans votre répertoire de travail actuel (où vous exécutez Jupyter : TP1) et utilisez le code suivant pour analyser le fichier csv. Notez les noms de colonnes et les types de données (U100, i4)\n"
      ],
      "id": "7Q0eOg3TZSp_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdXFSZaBZSp_",
        "outputId": "80c63148-f66f-403d-e7d6-0a7e656adbc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "dataset = np.loadtxt(\"sample_data/pl.csv\", dtype={'names': ('name', 'year'), \n",
        "       'formats': ('U100', 'i4')}, \n",
        "        skiprows=1, delimiter=\",\", encoding=\"UTF-8\") \n",
        "print(dataset)\n",
        "              "
      ],
      "id": "hdXFSZaBZSp_",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('ENIAC coding system', 1943) ('ENIAC Short Code', 1946)\n",
            " ('Von Neumann and Goldstine graphing system', 1946)\n",
            " ('ARC Assembly', 1947) ('Plankalkül', 1948) ('CPC Coding scheme', 1948)\n",
            " ('Curry notation system', 1948) ('Short Code', 1949)\n",
            " ('assembly language', 1949) ('Short Code', 1950) ('G-code', 1950)\n",
            " ('Birkbeck Assembler', 1950) ('Superplan', 1951) ('ALGAE', 1951)\n",
            " ('Intermediate Programming Language', 1951)\n",
            " ('Regional Assembly Language', 1951)\n",
            " ('Boehm unnamed coding system', 1951) ('Klammerausdrücke', 1951)\n",
            " ('OMNIBAC Symbolic Assembler', 1951) ('Stanislaus', 1951)\n",
            " ('Whirlwind assembler', 1951) ('Rochester assembler', 1951)\n",
            " ('Sort Merge Generator', 1951) ('autocode', 1952) ('A-0 System', 1952)\n",
            " ('Editing Generator', 1952) ('COMPOOL', 1952) ('Speedcoding', 1953)\n",
            " ('READ/PRINT', 1953) ('Fortran', 1954) ('ARITH-MATIC', 1954)\n",
            " ('autocode', 1954) ('Laning and Zierler system', 1954)\n",
            " ('MATH-MATIC', 1954) ('MATRIX MATH', 1954) ('FLOW-MATIC', 1955)\n",
            " ('PACT', 1955) ('BACAIC', 1955) ('Freiburger Code', 1955)\n",
            " ('Sequentielle Formelübersetzung', 1955) ('Internal Translator', 1955)\n",
            " ('PRINT', 1955) ('Information Processing Language', 1956)\n",
            " ('FORTRAN for the IBM 704', 1956) ('Fortran', 1957) ('COMTRAN', 1957)\n",
            " ('GEORGE', 1957) ('UNICODE', 1957) ('ALGOL 58', 1958) ('Lisp', 1958)\n",
            " ('ALGOL', 1958) ('FORTRAN III', 1958) ('FORTRAN II', 1958)\n",
            " ('JOVIAL', 1959) ('TRAC', 1959) ('COBOL', 1959) ('MAD', 1959)\n",
            " ('Lisp', 1959) ('FACT', 1959) ('COBOL', 1960) ('ALCOR', 1960)\n",
            " ('ALGOL 60', 1960) ('FORTRAN IV', 1961) ('TECO', 1962) ('SNOBOL', 1962)\n",
            " ('APL', 1962) ('Simula', 1962) ('CORC', 1962) ('CPL', 1963)\n",
            " ('JOSS', 1963) ('P′′', 1964) ('Report Program Generator', 1964)\n",
            " ('TRAC', 1964) ('BASIC', 1964) ('COWSEL', 1964) ('MARK IV', 1964)\n",
            " ('MIMIC', 1964) ('PL/I', 1964) ('Speakeasy', 1964) ('IBM RPG II', 1965)\n",
            " ('Atlas Autocode', 1965) ('TELCOMP', 1965) ('Euler', 1966)\n",
            " ('ISWIM', 1966) ('ALGOL W', 1966)\n",
            " ('Massachusetts General Hospital Utility Multi-Programming System', 1966)\n",
            " ('JOSS', 1966) ('Coral 66', 1966) ('BCPL', 1966) ('APL', 1966)\n",
            " ('FORTRAN 66', 1966)\n",
            " ('Massachusetts General Hospital Utility Multi-Programming System', 1967)\n",
            " ('Hop', 1967) ('XPL', 1967) ('Interlisp', 1967) ('BCPL', 1967)\n",
            " ('Simula', 1967) ('Space Programming Language', 1967) ('PILOT', 1968)\n",
            " ('ALGOL 68', 1968)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgvYmGVSZSp_"
      },
      "source": [
        "![](attachment:../../images/numpycsv.png)\n",
        "\n",
        "[Soutien du CSV en numpy](https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html)\n",
        "(**Ref:**\n",
        "(https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html))\n",
        "est différent du défaut de Python [CSV\n",
        "reader](https://docs.python.org/3.5/library/csv.html) (**Ref:**\n",
        "(https://docs.python.org/3.5/library/csv.html))\n",
        "en raison de sa capacité à prendre en charge les [types de données](https://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html)\n",
        "(**Ref:**\n",
        "(https://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html)).\n",
        "Avant de continuer, examinez en profondeur\n",
        "[numpy.loadtxt](https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html)\n",
        "(**Ref:**\n",
        "(https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html)).\n",
        "\n",
        "  \n",
        "\n",
        "Copier le fichier\n",
        "[pl.tsv](../../data/pl.tsv) dans votre répertoire de travail actuel et utilisez le code suivant pour analyser le fichier TSV.\n",
        "\n"
      ],
      "id": "jgvYmGVSZSp_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIy4DwD_ZSqA"
      },
      "source": [
        "import numpy as np \n",
        "dataset = np.loadtxt(\"../../data/pl.tsv\", dtype={'names': ('name', 'year'), \n",
        "       'formats': ('U100', 'i4')}, \n",
        "        skiprows=1, delimiter=\"\\t\", encoding=\"UTF-8\") \n",
        "print(dataset)"
      ],
      "id": "RIy4DwD_ZSqA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB5YJ7HwZSqA"
      },
      "source": [
        "Notez les changements dans le code ci-dessus par rapport au précédent. Un fichier TSV est un fichier séparé par des tabulations, c'est-à-dire que les valeurs des colonnes sont séparées par un\n",
        "tabulation ((\\t)).\n"
      ],
      "id": "TB5YJ7HwZSqA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEw-stp8ZSqA"
      },
      "source": [
        "#### Exercice 1.3\n",
        "\n",
        "La plupart des sources de données externes peuvent fournir leurs données au format JSON.\n",
        "Notre prochain exercice consiste à analyser les fichiers JSON. Copiez le fichier\n",
        "[pl.json](../../data/pl.json) à votre répertoire de travail actuel et utilisez le code suivant pour analyser le fichier JSON. Dans cet exercice, nous utilisons [Pandas python\n",
        "package](https://pandas.pydata.org/pandas-docs/stable/) (**Ref:**\n",
        "(https://pandas.pydata.org/pandas-docs/stable/)) d'analyser le fichier JSON pour obtenir un [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n",
        "(**Ref:**\n",
        "(https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)).\n",
        "Essayez d'utiliser des méthodes comme\n",
        "[transpose](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.transpose.html#pandas.DataFrame.transpose)\n",
        "(**Ref:**\n",
        "(https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.transpose.html#pandas.DataFrame.transpose)),\n",
        "[count](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.count.html#pandas.DataFrame.count)\n",
        "(**Ref:**\n",
        "(https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.count.html#pandas.DataFrame.count))\n",
        "etc.\n",
        "\n",
        "Avant de continuer cet exercice, veuillez vous entraîner à travailler avec des pandas.\n",
        "Consultez [10 minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
        "(**Ref:** (https://pandas.pydata.org/pandas-docs/stable/10min.html)).\n",
        "\n"
      ],
      "id": "kEw-stp8ZSqA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJeu4Fs3ZSqA"
      },
      "source": [
        "from pandas import json_normalize\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "data = json.load(open('../../data/pl.json'))\n",
        "dataframe = json_normalize(data)\n",
        "print(dataframe)"
      ],
      "id": "TJeu4Fs3ZSqA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0FUvicCZSqB"
      },
      "source": [
        "#### Exercice 1.4\n",
        "\n",
        "Dans cet exercice, nous examinerons comment télécharger des données à partir\n",
        "des sources de données externes utilisant des interfaces d'interrogation spéciales. Par exemple, les données ci-dessus ont été obtenues à partir de [Wikidata query](https://query.wikidata.org/) \n",
        "\n",
        "![](attachment:../../images/wikidataquery.png)\n",
        "\n",
        "Vous trouverez ci-dessous le code permettant de lire les données provenant d'une source externe. Utilisez ce\n",
        "[url](https://query.wikidata.org/sparql?query=SELECT%20%3FlanguageLabel%20(YEAR(%3Finception)%20as%20%3Fyear)%0AWHERE%0A%7B%0A%20%20%23instances%20of%20programming%20language%0A%20%20%3Flanguage%20wdt%3AP31%20wd%3AQ9143%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20wdt%3AP571%20%3Finception%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20rdfs%3Alabel%20%3FlanguageLabel.%0A%20%20FILTER(lang(%3FlanguageLabel)%20%3D%20%22en%22)%0A%7D%0AORDER%20BY%20%3Fyear%0ALIMIT%20100&format=json):\n",
        "(https://query.wikidata.org/sparql?query=SELECT%20%3FlanguageLabel%20(YEAR(%3Finception)%20as%20%3Fyear)%0AWHERE%0A%7B%0A%20%20%23instances%20of%20programming%20language%0A%20%20%3Flanguage%20wdt%3AP31%20wd%3AQ9143%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20wdt%3AP571%20%3Finception%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20rdfs%3Alabel%20%3FlanguageLabel.%0A%20%20FILTER(lang(%3FlanguageLabel)%20%3D%20%22en%22)%0A%7D%0AORDER%20BY%20%3Fyear%0ALIMIT%20100&format=json).\n",
        "\n"
      ],
      "id": "J0FUvicCZSqB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHIQ9CX8ZSqC"
      },
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://query.wikidata.org/sparql?query=SELECT%20%3FlanguageLabel%20(YEAR(%3Finception)%20as%20%3Fyear)%0AWHERE%0A%7B%0A%20%20%23instances%20of%20programming%20language%0A%20%20%3Flanguage%20wdt%3AP31%20wd%3AQ9143%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20wdt%3AP571%20%3Finception%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20rdfs%3Alabel%20%3FlanguageLabel.%0A%20%20FILTER(lang(%3FlanguageLabel)%20%3D%20%22en%22)%0A%7D%0AORDER%20BY%20%3Fyear%0ALIMIT%20100&format=json\"\n",
        "response = urllib.request.urlopen(url)\n",
        "responsedata =  json.loads(response.read().decode('utf-8'))\n",
        "\n",
        "array = []\n",
        "\n",
        "for data in responsedata['results']['bindings']:\n",
        "    array.append([data['year']['value'],\n",
        "     data['languageLabel']['value']])\n",
        "\n",
        "dataframe = pd.DataFrame(array,\n",
        "     columns=['year', 'languageLabel'])\n",
        "dataframe = dataframe.astype(dtype= {\"year\":\"<i4\",\n",
        "     \"languageLabel\":\"<U200\"})\n",
        "print(dataframe)"
      ],
      "id": "HHIQ9CX8ZSqC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhsWTvFmZSqC"
      },
      "source": [
        "#### Exercice 1.5\n",
        "\n",
        "Ce dernier exercice utilisera quelques analyses de données de base. Poursuivant avec le code de l'exercice 1.4, comptons le nombre de langages de programmation sortis en un an."
      ],
      "id": "FhsWTvFmZSqC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2X9nd_XZSqD"
      },
      "source": [
        "grouped = dataframe.groupby('year').count()\n",
        "print(grouped)"
      ],
      "id": "Y2X9nd_XZSqD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_WJtwDBZSqE"
      },
      "source": [
        "Vous pouvez également utiliser plusieurs fonctions d'agrégation en utilisant agg()"
      ],
      "id": "R_WJtwDBZSqE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYz2aSKnZSqE"
      },
      "source": [
        "grouped = dataframe.groupby('year').agg(['count'])\n",
        "print(grouped)"
      ],
      "id": "QYz2aSKnZSqE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fscno1fJZSqE"
      },
      "source": [
        "Jusqu'à présent, nous avons travaillé avec des tableaux à deux colonnes. Maintenant, nous nous concentrons sur des tableaux à trois colonnes (langage de programmation, année, paradigme). Copiez le fichier [plparadigm.json](../../data/plparadigm.json) dans votre répertoire de travail. Et testez le programme suivant."
      ],
      "id": "Fscno1fJZSqE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQy234VrZSqE"
      },
      "source": [
        "from pandas.io.json import json_normalize\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "jsondata = json.load(open('../../data/plparadigm.json'))\n",
        "array = []\n",
        "\n",
        "for data in jsondata:\n",
        "    array.append([data['year'],\n",
        "                  data['languageLabel'], data['paradigmLabel']])\n",
        "\n",
        "dataframe = pd.DataFrame(array,\n",
        "      columns=['year', 'languageLabel', 'paradigmLabel']) \n",
        "dataframe = dataframe.astype(dtype= {\"year\" : \"int64\",\n",
        "      \"languageLabel\" : \"<U200\", \"paradigmLabel\" : \"<U200\"})\n",
        "\n",
        "grouped = dataframe.groupby(['year',\n",
        "       'paradigmLabel']).agg(['count'])\n",
        "print(grouped)"
      ],
      "id": "qQy234VrZSqE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCf93DV-ZSqF"
      },
      "source": [
        "Testez maintenant le programme suivant. Comparez la différence de rendement."
      ],
      "id": "MCf93DV-ZSqF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaA6ctkcZSqF"
      },
      "source": [
        "grouped = dataframe.groupby(['paradigmLabel',\n",
        "       'year']).agg(['count'])\n",
        "print(grouped)"
      ],
      "id": "zaA6ctkcZSqF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffpOGJD2ZSqG"
      },
      "source": [
        "Votre prochain objectif est de lancer la requête suivante pour obtenir la population\n",
        "des informations sur les différents pays (limitées à 10000 lignes). Exécutez le\n",
        "suite à la requête sur [Wikidata query service](https://query.wikidata.org)\n",
        "et téléchargez le fichier JSON.\n"
      ],
      "id": "ffpOGJD2ZSqG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsVgsUyTZSqG"
      },
      "source": [
        "```\n",
        "SELECT DISTINCT ?countryLabel (YEAR(?date) as ?year) ?population\n",
        "WHERE {\n",
        " ?country wdt:P31 wd:Q6256; #Country \n",
        "   p:P1082 ?populationStatement;\n",
        "  rdfs:label ?countryLabel. #Label\n",
        " ?populationStatement ps:P1082 ?population; #population\n",
        "  pq:P585 ?date. #period in time\n",
        " FILTER(lang(?countryLabel)=\"en\") #Label in English\n",
        "}\n",
        "ORDER by ?countryLabel ?year\n",
        "LIMIT 10000\n",
        "```\n",
        "              \n",
        "\n"
      ],
      "id": "DsVgsUyTZSqG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxR1TqvXZSqG"
      },
      "source": [
        "Maintenant, calculez et affichez les informations suivantes (en utilisant différentes\n",
        "[opérations disponibles dans la bibliothèque des pandas] (https://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
        "(**Ref:**\n",
        "(https://pandas.pydata.org/pandas-docs/stable/10min.html))):\n",
        "\n",
        "1.  La population des pays dans l'ordre alphabétique de leur nom et\n",
        "    par ordre croissant d'année.\n",
        "2.  La dernière population disponible de chaque pays\n",
        "3.  Le pays ayant la population la plus faible et la plus élevée (compte tenu de la\n",
        "    population la plus récente)\n",
        "\n",
        "Votre prochain objectif est de lancer la requête suivante pour obtenir des informations relatives\n",
        "aux articles scientifiques publiés après 2010 (limité à 10 000 lignes). Lancer\n",
        "la requête suivante sur [Wikidata query service](https://query.wikidata.org) et téléchargez le fichier JSON.\n",
        "Il vous donne les informations suivantes relatives à la recherche scientifique\n",
        "article : titre, sujet principal et année de publication.\n"
      ],
      "id": "jxR1TqvXZSqG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et853jvoZSqH"
      },
      "source": [
        "```\n",
        "SELECT ?title ?subjectLabel ?year\n",
        "{\n",
        "  ?article wdt:P31 wd:Q13442814; #scientific article\n",
        "           wdt:P1476 ?title; #title of the article\n",
        "           wdt:P921 ?subject; #main subject\n",
        "           wdt:P577 ?date. #publication date\n",
        "  ?subject rdfs:label ?subjectLabel.\n",
        "  BIND(YEAR(?date) as ?year).\n",
        "  #published after 2010\n",
        "  FILTER(lang(?title)=\"en\" &&\n",
        "     lang(?subjectLabel)=\"en\" && ?year>2010)\n",
        "}\n",
        "LIMIT 10000\n",
        "```\n",
        "\n"
      ],
      "id": "et853jvoZSqH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpYd05hoZSqH"
      },
      "source": [
        "Maintenant, calculez et affichez les informations suivantes (en utilisant diverses [opérations disponibles dans la bibliothèque des pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
        "(**Ref:**\n",
        "(https://pandas.pydata.org/pandas-docs/stable/10min.html))):\n",
        "\n",
        "1.  Le nombre d'articles publiés sur différents sujets chaque année.\n",
        "2.  Principal sujet d'intérêt pour la communauté scientifique chaque année (sur la base\n",
        "    sur les résultats de l'interrogation ci-dessus).\n",
        "3.  Les 10 principaux sujets d'intérêt pour la communauté scientifique (sur la base\n",
        "    les résultats de l'interrogation ci-dessus) depuis 2010.\n",
        "\n",
        "(Indice :) Regardez les fonctions groupby, reset_index, head, tail, sort_values, count de Pandas\n",
        "\n"
      ],
      "id": "QpYd05hoZSqH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYjXQs4sZSqH"
      },
      "source": [
        ""
      ],
      "id": "ZYjXQs4sZSqH",
      "execution_count": null,
      "outputs": []
    }
  ]
}